{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GENERATED CODE FOR multipletransformation PIPELINE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DON'T EDIT THIS CODE.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CONNECTOR FUNCTIONS TO READ DATA.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs3 import HDFileSystem\n",
    "import datetime\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class HDFSConnector:\n",
    "\n",
    "    def fetch(spark, config):\n",
    "        ################### INPUT HADOOP HOST PORT TO CONNECT WITH ###############################\n",
    "        hdfs = HDFileSystem(\n",
    "            host=eval(config)['host'], port=eval(config)['port'])\n",
    "        with hdfs.open(eval(config)['url']) as f:\n",
    "            df = pd.read_csv(f, error_bad_lines=False)\n",
    "        df = spark.createDataFrame(dfPd)\n",
    "        display(df.limit(2).toPandas())\n",
    "        return df\n",
    "\n",
    "    def put(df, spark, config):\n",
    "        return df.write.format('csv').options(header='true' if eval(config)[\"is_header\"] == \"Use Header Line\" else 'false',\n",
    "                                              delimiter=eval(config)[\"delimiter\"]).save((\"%s %s\") % (datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")+\"_\", eval(config)['url']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OPERATION FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Where:\n",
    "    custom = False\n",
    "    column1Name = \"column1Name\"\n",
    "    column2Name = \"column2Name\"\n",
    "    customValue = \"customValue\"\n",
    "    valueType = \"valueType\"\n",
    "    operator = \"operator\"\n",
    "    combinator = \"combinator\"\n",
    "\n",
    "    def __init__(self, custom, column1Name, column2Name, customValue, valueType, operator, combinator):\n",
    "        self.custom = custom\n",
    "        self.column1Name = column1Name\n",
    "        self.column2Name = column2Name\n",
    "        self.customValue = customValue\n",
    "        self.valueType = valueType\n",
    "        self.operator = operator\n",
    "        self.combinator = combinator\n",
    "\n",
    "\n",
    "class FilterOperation:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(attributes):\n",
    "        filters = []\n",
    "        for filter in attributes[\"expression\"]:\n",
    "            filters.append(Where(filter[\"custom\"],\n",
    "                                 filter[\"column1_name\"] or None,\n",
    "                                 filter[\"column2_name\"] or None,\n",
    "                                 filter[\"custom_value\"] or None,\n",
    "                                 filter[\"value_type\"] or None,\n",
    "                                 filter[\"operator\"] or None,\n",
    "                                 filter[\"combinator\"] or \"\"))\n",
    "        return filters\n",
    "\n",
    "    def run(inStages, inStagesData, stageId, sparkSession, stageAttribs):\n",
    "        filters = FilterOperation.parse(eval(stageAttribs))\n",
    "        whereClause = \"\"\n",
    "        for f in filters:\n",
    "            if f.custom:\n",
    "                customValue = f.customValue\n",
    "                if f.valueType.lower() == \"string\":\n",
    "                    customValue = \"'\" + customValue + \"'\"\n",
    "                whereClause += \"%s %s %s %s \" % (f.combinator,\n",
    "                                                 f.column1Name, f.operator, customValue)\n",
    "            else:\n",
    "                whereClause += \"%s %s %s %s \" % (f.combinator,\n",
    "                                                 f.column1Name, f.operator, f.column2Name)\n",
    "\n",
    "        inStagesData[inStages[0]].createOrReplaceTempView(\"view%s\" % (stageId))\n",
    "        query = \"SELECT * FROM %s WHERE %s\" % (\"view%s\" %\n",
    "                                               (stageId), whereClause)\n",
    "        return sparkSession.sql(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OPERATION FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from dask.dataframe import from_pandas\n",
    "import json\n",
    "\n",
    "\n",
    "def replaceValues(df, functionsData, applyOn):\n",
    "    for columnData in applyOn:\n",
    "        for functionData in functionsData:\n",
    "            if functionData['replaceType'] == 'value':\n",
    "                if functionData['replaceValueType'] == 'min':\n",
    "                    minValue = df[columnData['columnName']].min().compute()\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, minValue)\n",
    "                elif functionData['replaceValueType'] == 'max':\n",
    "                    maxValue = df[columnData['columnName']].max().compute()\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, maxValue)\n",
    "                else:\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        toReplace, functionData['ReplaceWith'])\n",
    "            elif functionData['replaceType'] == 'none':\n",
    "                if functionData['replaceValueType'] == 'min':\n",
    "                    minValue = df[columnData['columnName']].min().compute()\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].replace(\"\", minValue)\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].fillna(minValue)\n",
    "                elif functionData['replaceValueType'] == 'max':\n",
    "                    maxValue = df[columnData['columnName']].max().compute()\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].replace(\"\", maxValue)\n",
    "                    df[columnData['columnName']\n",
    "                       ] = df[columnData['columnName']].fillna(maxValue)\n",
    "                else:\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].replace(\n",
    "                        \"\", functionData['ReplaceWith'])\n",
    "                    df[columnData['columnName']] = df[columnData['columnName']].fillna(\n",
    "                        functionData['ReplaceWith'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def runDataCleansing(sparkDf, spark, config):\n",
    "    configObj = json.loads(config)\n",
    "    sparkDf.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = from_pandas((sparkDf.toPandas()), npartitions=5)\n",
    "    functionList = configObj['functionsApplied']\n",
    "    Data_Cleansing_Methods = {\"replaceBy\": replaceValues,\n",
    "                              \"formula\": calculateFormula,\n",
    "                              \"aggregate\": aggregation,\n",
    "                              \"converttostringtype\": changeToString,\n",
    "                              \"editname\": renameColumns}\n",
    "    for function in functionList:\n",
    "        function['functionName']\n",
    "        df = Data_Cleansing_Methods[function['functionName']](df, function['functionsData'],\n",
    "                                                              function['applyOn'])\n",
    "    sparkDf = spark.createDataFrame(df.compute())\n",
    "\n",
    "    display(sparkDf.limit(2).toPandas())\n",
    "    return sparkDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRANSFORMATIONS FUNCTIONS THAT WILL BE APPLIED ON DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import mean, stddev, min, max, col\n",
    "\n",
    "\n",
    "class CleanseData:\n",
    "    # def __init__(self,df):\n",
    "    #     #print()\n",
    "\n",
    "    def replaceByMean(self, feature, df, mean_=-1):\n",
    "\n",
    "        meanValue = df.select(mean(col(feature.name)).alias(\n",
    "            'mean')).collect()[0][\"mean\"]\n",
    "        df.fillna(meanValue, subset=[feature.name])\n",
    "        df.withColumn(feature.name, when(col(feature.name) == \" \",\n",
    "                                         meanValue).otherwise(col(feature.name).cast(\"Integer\")))\n",
    "        return df\n",
    "\n",
    "    def replaceByMax(self, feature, df, max_=-1):\n",
    "        maxValue = df.select(max(col(feature.name)).alias('max')).collect()[\n",
    "            0][\"max\"]\n",
    "        df.fillna(maxValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", maxValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceByMin(self, feature, df, min_=-1):\n",
    "        minValue = df.select(min(col(feature.name)).alias('min')).collect()[\n",
    "            0][\"min\"]\n",
    "        df.fillna(minValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", minValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceByStandardDeviation(self, feature, df, stddev_=-1):\n",
    "        stddevValue = df.select(stddev(col(feature.name)).alias(\n",
    "            'stddev')).collect()[0][\"stddev\"]\n",
    "        df.fillna(stddevValue, subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", stddevValue).otherwise(col(feature.name)))\n",
    "        return df\n",
    "\n",
    "    def replaceDateRandomly(self, feature, df):\n",
    "        fillValue = df.where(col(feature.name).isNotNull()\n",
    "                             ).head(1)[0][feature.name]\n",
    "        df.fillna(str(fillValue), subset=[feature.name])\n",
    "        df = df.withColumn(feature.name,\n",
    "                           when(col(feature.name) == \" \", fillValue).otherwise(col(feature.name)))\n",
    "        # print(\"CleanseData:replaceDateRandomly Schema : \", df.#printSchema())\n",
    "        return df\n",
    "\n",
    "    def replaceNullValues(self, fList, df):\n",
    "        featuresList = df.schema.fields\n",
    "        for featureObj in fList:\n",
    "            for feat in featuresList:\n",
    "                if featureObj[\"feature\"] in feat.name:\n",
    "                    featureName = feat\n",
    "                    if \"mean\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMean(featureName, df)\n",
    "                    elif \"max\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMax(featureName, df)\n",
    "                    elif \"min\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByMin(featureName, df)\n",
    "                    elif \"stddev\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceByStandardDeviation(featureName, df)\n",
    "                    elif \"random\" in featureObj[\"replaceby\"]:\n",
    "                        df = self.replaceDateRandomly(featureName, df)\n",
    "        return df\n",
    "\n",
    "\n",
    "def StringIndexerTransform(df, params, transformationData={}):\n",
    "    dfReturn = df\n",
    "    feature = params[\"feature\"]\n",
    "\n",
    "    dfReturn = dfReturn.fillna({feature: ''})\n",
    "    outcol = feature + \"_stringindexer\"\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=feature, outputCol=outcol, handleInvalid=\"skip\")\n",
    "    indexed = indexer.fit(dfReturn).transform(dfReturn)\n",
    "    dfReturn = indexed\n",
    "    distinct_values_list = dfReturn.select(\n",
    "        outcol).distinct().rdd.map(lambda r: r[0]).collect()\n",
    "    len_distinct_values_list = len(distinct_values_list)\n",
    "    if len_distinct_values_list <= 4:\n",
    "        changed_type_df = dfReturn.withColumn(\n",
    "            outcol, dfReturn[outcol].cast(IntegerType()))\n",
    "        return changed_type_df\n",
    "    return dfReturn\n",
    "\n",
    "\n",
    "class TransformationMain:\n",
    "    # TODO: change df argument in run with following\n",
    "    def run(transformationDF, config):\n",
    "        configObj = json.loads(config)\n",
    "        featureData = configObj[\"FE\"]\n",
    "        transformationDF = CleanseData().replaceNullValues(featureData, transformationDF)\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'State', 'transformation_label': 'String Indexer'}], 'feature': 'State', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "                                                  'count': '3332', 'mean': '', 'stddev': '', 'min': 'AK', 'max': 'WY', 'missing': '0'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'State'}, {'feature_label': 'State', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('State')\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'Phone', 'transformation_label': 'String Indexer'}], 'feature': 'Phone', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '3332', 'mean': '', 'stddev': '', 'min': '327-1058', 'max': '422-9964', 'missing': '0'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'Phone'}, {'feature_label': 'Phone', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('Phone')\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'Intl_Plan', 'transformation_label': 'String Indexer'}], 'feature': 'Intl_Plan', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '3332', 'mean': '', 'stddev': '', 'min': 'no', 'max': 'yes', 'missing': '0'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'Intl_Plan'}, {'feature_label': 'Intl_Plan', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('Intl_Plan')\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'VMail_Plan', 'transformation_label': 'String Indexer'}], 'feature': 'VMail_Plan', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '3332', 'mean': '', 'stddev': '', 'min': 'no', 'max': 'yes', 'missing': '0'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'VMail_Plan'}, {'feature_label': 'VMail_Plan', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('VMail_Plan')\n",
    "        transformationDF = StringIndexerTransform(transformationDF, {'transformationsData': [{'feature_label': 'cluster_labels', 'transformation_label': 'String Indexer'}], 'feature': 'cluster_labels', 'type': 'string', 'selected': 'True', 'replaceby': 'max', 'stats': {\n",
    "            'count': '3332', 'mean': '', 'stddev': '', 'min': 'day_callers', 'max': 'vmailers', 'missing': '0'}, 'transformation': [{'transformation': 'String Indexer', 'selectedAsDefault': 1}], 'updatedLabel': 'cluster_labels'}, {'feature_label': 'cluster_labels', 'transformation_label': 'String Indexer'})\n",
    "        transformationDF = transformationDF.drop('cluster_labels')\n",
    "        display(transformationDF.limit(2).toPandas())\n",
    "        return transformationDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***AUTOML FUNCTIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyspark\n",
    "\n",
    "\n",
    "def functionClassification(sparkDF, listOfFeatures, label):\n",
    "    sparkDF.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "    df = (sparkDF.toPandas())\n",
    "    X = (df.drop(label, axis=1))[listOfFeatures].values\n",
    "    y = df[label].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1, test_size=0.1)\n",
    "    tpotModel = TPOTClassifier(verbosity=3, n_jobs=-1, generations=10, max_time_mins=5,\n",
    "                               population_size=15)\n",
    "    tpotModel.fit(X_train, y_train)\n",
    "    display(\" Accuracy of Model : %s\" % tpotModel.score(X_test, y_test))\n",
    "    data = {'model': tpotModel,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'label': label,\n",
    "            'columnNames': listOfFeatures}\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***READING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## CREATE SPARK SESSION ############################ ENTER YOUR SPARK MASTER IP AND PORT TO CONNECT TO SERVER ################from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('spark://0.0.0.0:0000').getOrCreate()\n",
    "#%run multipletransformationHooks.ipynb\n",
    "try:\n",
    "\t#sourcePreExecutionHook()\n",
    "\n",
    "\tpredictivechurntrain = HDFSConnector.fetch(spark, \"{'url': '/FileStore/platform/Data/TrainData/PredictiveChurnTrain.csv', 'filename': 'PredictiveChurnTrain.csv', 'delimiter': ',', 'file_type': 'Delimeted', 'is_header': 'Use Header Line', 'server_url': '/numtraPlatform/NumtraPlatformV2/uploads/platform/'}\")\n",
    "\t#sourcePostExecutionHook(predictivechurntrain)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PERFORMING OPERATIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run multipletransformationHooks.ipynb\n",
    "try:\n",
    "\tfilter = FilterOperation.run([\"60cc86c0b1e28e47f2c45be1\"],{\"60cc86c0b1e28e47f2c45be1\": predictivechurntrain}, \"60cc86c7b1e28e47f2c45be2\", spark, \"{'url': '/FileStore/platform/Data/TrainData/PredictiveChurnTrain.csv', 'expression': [{'column1_name': 'Intl_Plan', 'operator': '=', 'column2_name': 'VMail_Plan', 'custom': False, 'custom_value': '', 'value_type': '', 'combinator': '', 'showOptions': True}], 'use_expression': True, 'regex': [], 'use_regex': False, 'server_url': '/numtraPlatform/NumtraPlatformV2/uploads/platform/'}\")\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PERFORMING OPERATIONS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run multipletransformationHooks.ipynb\n",
    "try:\n",
    "\t#operationPreExecutionHook()\n",
    "\n",
    "datapreparation = runDataCleansing(filter,spark,json.dumps( {\"url\": \"/FileStore/platform/Data/TrainData/PredictiveChurnTrain.csv\", \"source_attributes\": {}, \"DataPrepFile\": \"/FileStore/platform/Data/TrainData/PredictiveChurnTrain.csv\", \"data_source\": \"HDFS\", \"startListenerOnly\": 1, \"dateColumnNames\": [], \"FilePath\": \"/FileStore/platform/extra/60cc86cdb1e28e47f2c45be31624017132/0part.csv\", \"requestRatio\": 7.0, \"totalRows\": 3332, \"BasicStats\": {\"missingValues\": 0.0, \"numberOfColumns\": 24, \"numberOfRows\": 3332, \"duplicateRowCount\": 0, \"stats\": [{\"column\": \"State\", \"alias\": \"State\", \"generated\": 0, \"type\": \"String\", \"max\": \"WY\", \"min\": \"AK\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\"}, {\"column\": \"Account_Length\", \"alias\": \"Account_Length\", \"generated\": 0, \"type\": \"real\", \"max\": 243.0, \"min\": 1.0, \"mean\": 101.05672268907563, \"missing\": 0.0, \"stddev\": 39.83}, {\"column\": \"Area_Code\", \"alias\": \"Area_Code\", \"generated\": 0, \"type\": \"real\", \"max\": 510.0, \"min\": 408.0, \"mean\": 437.1890756302521, \"missing\": 0.0, \"stddev\": 42.38}, {\"column\": \"Phone\", \"alias\": \"Phone\", \"generated\": 0, \"type\": \"String\", \"max\": \"422-9964\", \"min\": \"327-1058\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\"}, {\"column\": \"Intl_Plan\", \"alias\": \"Intl_Plan\", \"generated\": 0, \"type\": \"String\", \"max\": \"yes\", \"min\": \"no\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\"}, {\"column\": \"VMail_Plan\", \"alias\": \"VMail_Plan\", \"generated\": 0, \"type\": \"String\", \"max\": \"yes\", \"min\": \"no\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\"}, {\"column\": \"VMail_Message\", \"alias\": \"VMail_Message\", \"generated\": 0, \"type\": \"real\", \"max\": 51.0, \"min\": 0.0, \"mean\": 8.093937575030012, \"missing\": 0.0, \"stddev\": 13.69}, {\"column\": \"Day_Mins\", \"alias\": \"Day_Mins\", \"generated\": 0, \"type\": \"real\", \"max\": 350.8, \"min\": 0.0, \"mean\": 179.74948979591855, \"missing\": 0.0, \"stddev\": 54.46}, {\"column\": \"Day_Calls\", \"alias\": \"Day_Calls\", \"generated\": 0, \"type\": \"real\", \"max\": 165.0, \"min\": 0.0, \"mean\": 100.4327731092437, \"missing\": 0.0, \"stddev\": 20.07}, {\"column\": \"Day_Charge\", \"alias\": \"Day_Charge\", \"generated\": 0, \"type\": \"real\", \"max\": 59.64, \"min\": 0.0, \"mean\": 30.557953181272534, \"missing\": 0.0, \"stddev\": 9.26}, {\"column\": \"Eve_Mins\", \"alias\": \"Eve_Mins\", \"generated\": 0, \"type\": \"real\", \"max\": 363.7, \"min\": 0.0, \"mean\": 200.98142256902753, \"missing\": 0.0, \"stddev\": 50.72}, {\"column\": \"Eve_Calls\", \"alias\": \"Eve_Calls\", \"generated\": 0, \"type\": \"real\", \"max\": 170.0, \"min\": 0.0, \"mean\": 100.11464585834334, \"missing\": 0.0, \"stddev\": 19.93}, {\"column\": \"Eve_Charge\", \"alias\": \"Eve_Charge\", \"generated\": 0, \"type\": \"real\", \"max\": 30.91, \"min\": 0.0, \"mean\": 17.083631452581024, \"missing\": 0.0, \"stddev\": 4.31}, {\"column\": \"Night_Mins\", \"alias\": \"Night_Mins\", \"generated\": 0, \"type\": \"real\", \"max\": 395.0, \"min\": 23.2, \"mean\": 200.8588835534214, \"missing\": 0.0, \"stddev\": 50.58}, {\"column\": \"Night_Calls\", \"alias\": \"Night_Calls\", \"generated\": 0, \"type\": \"real\", \"max\": 175.0, \"min\": 33.0, \"mean\": 100.11044417767107, \"missing\": 0.0, \"stddev\": 19.57}, {\"column\": \"Night_Charge\", \"alias\": \"Night_Charge\", \"generated\": 0, \"type\": \"real\", \"max\": 17.77, \"min\": 1.04, \"mean\": 9.038733493397373, \"missing\": 0.0, \"stddev\": 2.28}, {\"column\": \"Intl_Mins\", \"alias\": \"Intl_Mins\", \"generated\": 0, \"type\": \"real\", \"max\": 20.0, \"min\": 0.0, \"mean\": 10.237364945978387, \"missing\": 0.0, \"stddev\": 2.79}, {\"column\": \"total_Mins\", \"alias\": \"total_Mins\", \"generated\": 0, \"type\": \"real\", \"max\": 885.0, \"min\": 284.3, \"mean\": 591.8271608643462, \"missing\": 0.0, \"stddev\": 89.94}, {\"column\": \"Intl_Calls\", \"alias\": \"Intl_Calls\", \"generated\": 0, \"type\": \"real\", \"max\": 20.0, \"min\": 0.0, \"mean\": 4.479891956782713, \"missing\": 0.0, \"stddev\": 2.46}, {\"column\": \"Intl_Charge\", \"alias\": \"Intl_Charge\", \"generated\": 0, \"type\": \"real\", \"max\": 5.4, \"min\": 0.0, \"mean\": 2.764600840336124, \"missing\": 0.0, \"stddev\": 0.75}, {\"column\": \"Total_Charge\", \"alias\": \"Total_Charge\", \"generated\": 0, \"type\": \"real\", \"max\": 96.15, \"min\": 22.93, \"mean\": 59.444918967586965, \"missing\": 0.0, \"stddev\": 10.5}, {\"column\": \"CustServ_Calls\", \"alias\": \"CustServ_Calls\", \"generated\": 0, \"type\": \"real\", \"max\": 9.0, \"min\": 0.0, \"mean\": 1.5630252100840336, \"missing\": 0.0, \"stddev\": 1.32}, {\"column\": \"Churn\", \"alias\": \"Churn\", \"generated\": 0, \"type\": \"real\", \"max\": 1.0, \"min\": 0.0, \"mean\": 0.14495798319327732, \"missing\": 0.0, \"stddev\": 0.35}, {\"column\": \"cluster_labels\", \"alias\": \"cluster_labels\", \"generated\": 0, \"type\": \"String\", \"max\": \"vmailers\", \"min\": \"day_callers\", \"mean\": \"\", \"missing\": 0.0, \"stddev\": \"\"}]}, \"HasBasicStats\": 1, \"functionsApplied\": [{\"functionName\": \"replaceBy\", \"applyOn\": [{\"columnName\": \"Intl_Plan\", \"type\": \"String\", \"min\": \"no\", \"max\": \"yes\", \"mean\": \"-\"}], \"functionsData\": [{\"replaceType\": \"none\", \"toReplace\": \"\", \"asNewColumn\": 0, \"newColumnName\": \"\", \"replaceValueType\": \"max\", \"ReplaceWith\": \"\"}]}], \"functionChanges\": [{\"columnName\": \"Intl_Plan\", \"functionName\": \"Replace Outliers\", \"Type\": \"String\", \"Parameters\": [{\"replaceType\": \"none\", \"toReplace\": \"\", \"asNewColumn\": 0, \"newColumnName\": \"\", \"replaceValueType\": \"max\", \"ReplaceWith\": \"\"}]}], \"fileheader\": [{\"field\": \"State\", \"alias\": \"State\", \"generated\": 0, \"position\": 1, \"type\": \"String\"}, {\"field\": \"Account_Length\", \"alias\": \"Account_Length\", \"generated\": 0, \"position\": 2, \"type\": \"real\"}, {\"field\": \"Area_Code\", \"alias\": \"Area_Code\", \"generated\": 0, \"position\": 3, \"type\": \"real\"}, {\"field\": \"Phone\", \"alias\": \"Phone\", \"generated\": 0, \"position\": 4, \"type\": \"String\"}, {\"field\": \"Intl_Plan\", \"alias\": \"Intl_Plan\", \"generated\": 0, \"position\": 5, \"type\": \"String\"}, {\"field\": \"VMail_Plan\", \"alias\": \"VMail_Plan\", \"generated\": 0, \"position\": 6, \"type\": \"String\"}, {\"field\": \"VMail_Message\", \"alias\": \"VMail_Message\", \"generated\": 0, \"position\": 7, \"type\": \"real\"}, {\"field\": \"Day_Mins\", \"alias\": \"Day_Mins\", \"generated\": 0, \"position\": 8, \"type\": \"real\"}, {\"field\": \"Day_Calls\", \"alias\": \"Day_Calls\", \"generated\": 0, \"position\": 9, \"type\": \"real\"}, {\"field\": \"Day_Charge\", \"alias\": \"Day_Charge\", \"generated\": 0, \"position\": 10, \"type\": \"real\"}, {\"field\": \"Eve_Mins\", \"alias\": \"Eve_Mins\", \"generated\": 0, \"position\": 11, \"type\": \"real\"}, {\"field\": \"Eve_Calls\", \"alias\": \"Eve_Calls\", \"generated\": 0, \"position\": 12, \"type\": \"real\"}, {\"field\": \"Eve_Charge\", \"alias\": \"Eve_Charge\", \"generated\": 0, \"position\": 13, \"type\": \"real\"}, {\"field\": \"Night_Mins\", \"alias\": \"Night_Mins\", \"generated\": 0, \"position\": 14, \"type\": \"real\"}, {\"field\": \"Night_Calls\", \"alias\": \"Night_Calls\", \"generated\": 0, \"position\": 15, \"type\": \"real\"}, {\"field\": \"Night_Charge\", \"alias\": \"Night_Charge\", \"generated\": 0, \"position\": 16, \"type\": \"real\"}, {\"field\": \"Intl_Mins\", \"alias\": \"Intl_Mins\", \"generated\": 0, \"position\": 17, \"type\": \"real\"}, {\"field\": \"total_Mins\", \"alias\": \"total_Mins\", \"generated\": 0, \"position\": 18, \"type\": \"real\"}, {\"field\": \"Intl_Calls\", \"alias\": \"Intl_Calls\", \"generated\": 0, \"position\": 19, \"type\": \"real\"}, {\"field\": \"Intl_Charge\", \"alias\": \"Intl_Charge\", \"generated\": 0, \"position\": 20, \"type\": \"real\"}, {\"field\": \"Total_Charge\", \"alias\": \"Total_Charge\", \"generated\": 0, \"position\": 21, \"type\": \"real\"}, {\"field\": \"CustServ_Calls\", \"alias\": \"CustServ_Calls\", \"generated\": 0, \"position\": 22, \"type\": \"real\"}, {\"field\": \"Churn\", \"alias\": \"Churn\", \"generated\": 0, \"position\": 23, \"type\": \"real\"}, {\"field\": \"cluster_labels\", \"alias\": \"cluster_labels\", \"generated\": 0, \"position\": 24, \"type\": \"String\"}]}))\n",
    "\t#operationPostExecutionHook(datapreparation)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRANSFORMING DATAFRAME***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run multipletransformationHooks.ipynb\n",
    "try:\n",
    "\t#transformationPreExecutionHook()\n",
    "\n",
    "\tautofe = TransformationMain.run(datapreparation,json.dumps( {\"FE\": [{\"transformationsData\": [{\"feature_label\": \"State\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"State\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"3332\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"AK\", \"max\": \"WY\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"State\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Account_Length\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"101.06\", \"stddev\": \"39.83\", \"min\": \"1.0\", \"max\": \"243.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Account_Length\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Area_Code\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"437.19\", \"stddev\": \"42.38\", \"min\": \"408.0\", \"max\": \"510.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Area_Code\"}, {\"transformationsData\": [{\"feature_label\": \"Phone\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"Phone\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"3332\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"327-1058\", \"max\": \"422-9964\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Phone\"}, {\"transformationsData\": [{\"feature_label\": \"Intl_Plan\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"Intl_Plan\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"3332\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"no\", \"max\": \"yes\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Intl_Plan\"}, {\"transformationsData\": [{\"feature_label\": \"VMail_Plan\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"VMail_Plan\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"3332\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"no\", \"max\": \"yes\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"VMail_Plan\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"VMail_Message\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"8.09\", \"stddev\": \"13.69\", \"min\": \"0.0\", \"max\": \"51.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"VMail_Message\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Day_Mins\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"179.75\", \"stddev\": \"54.46\", \"min\": \"0.0\", \"max\": \"350.8\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Day_Mins\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Day_Calls\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"100.43\", \"stddev\": \"20.07\", \"min\": \"0.0\", \"max\": \"165.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Day_Calls\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Day_Charge\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"30.56\", \"stddev\": \"9.26\", \"min\": \"0.0\", \"max\": \"59.64\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Day_Charge\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eve_Mins\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"200.98\", \"stddev\": \"50.72\", \"min\": \"0.0\", \"max\": \"363.7\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eve_Mins\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eve_Calls\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"100.11\", \"stddev\": \"19.93\", \"min\": \"0.0\", \"max\": \"170.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eve_Calls\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Eve_Charge\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"17.08\", \"stddev\": \"4.31\", \"min\": \"0.0\", \"max\": \"30.91\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Eve_Charge\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Night_Mins\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"200.86\", \"stddev\": \"50.58\", \"min\": \"23.2\", \"max\": \"395.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Night_Mins\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Night_Calls\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"100.11\", \"stddev\": \"19.57\", \"min\": \"33.0\", \"max\": \"175.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Night_Calls\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Night_Charge\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"9.04\", \"stddev\": \"2.28\", \"min\": \"1.04\", \"max\": \"17.77\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Night_Charge\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Intl_Mins\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"10.24\", \"stddev\": \"2.79\", \"min\": \"0.0\", \"max\": \"20.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Intl_Mins\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"total_Mins\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"591.83\", \"stddev\": \"89.94\", \"min\": \"284.3\", \"max\": \"885.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"total_Mins\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Intl_Calls\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"4.48\", \"stddev\": \"2.46\", \"min\": \"0.0\", \"max\": \"20.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Intl_Calls\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Intl_Charge\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"2.76\", \"stddev\": \"0.75\", \"min\": \"0.0\", \"max\": \"5.4\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Intl_Charge\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Total_Charge\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"59.44\", \"stddev\": \"10.5\", \"min\": \"22.93\", \"max\": \"96.15\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Total_Charge\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"CustServ_Calls\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"1.56\", \"stddev\": \"1.32\", \"min\": \"0.0\", \"max\": \"9.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"CustServ_Calls\"}, {\"transformationsData\": [{\"transformation_label\": \"novalue\"}], \"feature\": \"Churn\", \"type\": \"real\", \"selected\": \"True\", \"replaceby\": \"mean\", \"stats\": {\"count\": \"3332\", \"mean\": \"0.14\", \"stddev\": \"0.35\", \"min\": \"0.0\", \"max\": \"1.0\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"novalue\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"Churn\"}, {\"transformationsData\": [{\"feature_label\": \"cluster_labels\", \"transformation_label\": \"String Indexer\"}], \"feature\": \"cluster_labels\", \"type\": \"string\", \"selected\": \"True\", \"replaceby\": \"max\", \"stats\": {\"count\": \"3332\", \"mean\": \"\", \"stddev\": \"\", \"min\": \"day_callers\", \"max\": \"vmailers\", \"missing\": \"0\"}, \"transformation\": [{\"transformation\": \"String Indexer\", \"selectedAsDefault\": 1}], \"updatedLabel\": \"cluster_labels\"}]}))\n",
    "\n",
    "\t#transformationPostExecutionHook(autofe)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TRAIN MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run multipletransformationHooks.ipynb\n",
    "try:\n",
    "\t#mlPreExecutionHook()\n",
    "\n",
    "\tdataAutoML=functionClassification(autofe, [\"State_stringindexer\", \"Account_Length\", \"Area_Code\", \"Phone_stringindexer\", \"Intl_Plan_stringindexer\", \"VMail_Plan_stringindexer\", \"VMail_Message\", \"Day_Mins\", \"Day_Calls\", \"Day_Charge\", \"Eve_Mins\", \"Eve_Calls\", \"Eve_Charge\", \"Night_Mins\", \"Night_Calls\", \"Night_Charge\", \"Intl_Mins\", \"total_Mins\", \"Intl_Calls\", \"Intl_Charge\", \"Total_Charge\", \"CustServ_Calls\", \"cluster_labels_stringindexer\"], \"Churn\")\n",
    "\n",
    "\t#mlPostExecutionHook(dataAutoML)\n",
    "\n",
    "except Exception as ex: \n",
    "\tlogging.error(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PREDICT ON TRAINED MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "try:\n",
    "    model=dataAutoML['model']\n",
    "    X_test=dataAutoML['X_test']\n",
    "    y_test=dataAutoML['y_test']\n",
    "    label=dataAutoML['label']\n",
    "    columnNames=dataAutoML['columnNames']\n",
    "    if label in columnNames:\n",
    "        columnNames.remove(label)\n",
    "    predicted=label+\"_predicted\"\n",
    "    y_predicted=model.predict(X_test)\n",
    "    df =pd.DataFrame(X_test , columns=columnNames)\n",
    "    df[label]=y_test\n",
    "    df[predicted]=y_predicted\n",
    "    columnNames.insert(0,predicted)\n",
    "    columnNames.insert(0,label)\n",
    "    Accuracy = np.round((100 * sklearn.metrics.accuracy_score(y_true=y_test, y_pred=y_predicted)), 1)\n",
    "    F1= np.round(\n",
    "            (100 * sklearn.metrics.f1_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    Precision= np.round((\n",
    "                100 * sklearn.metrics.precision_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    Recall = np.round((\n",
    "                100 * sklearn.metrics.recall_score(y_true=y_test, y_pred=y_predicted, average=\"weighted\")), 1)\n",
    "    display(\" Accuracy of Prediction on test data    : %s\"%Accuracy)\n",
    "    display(\" F1 score of Prediction on test data    : %s\"%F1)\n",
    "    display(\" Precision of Prediction on test data   : %s\"%Precision)\n",
    "    display(\" Recall of Prediction on test data      : %s\"%Recall)\n",
    "    display(df.head())\n",
    "except Exception as ex:\n",
    "    logging.error(ex)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
